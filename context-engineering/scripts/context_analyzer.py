#!/usr/bin/env python3
"""
Context Analyzer Script

Analyzes current context usage and provides optimization recommendations.

Usage:
    python context_analyzer.py --session-file /path/to/session.json
    python context_analyzer.py --doc-dir /path/to/project
"""

import argparse
import os
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Optional


@dataclass
class ContextMetrics:
    """Metrics about current context usage."""
    total_tokens: int
    conversation_tokens: int
    documentation_tokens: int
    memory_tokens: int
    tool_output_tokens: int
    estimated_usage_percent: float
    message_count: int
    session_duration_minutes: float


@dataclass 
class ContextRecommendation:
    """A recommendation for context optimization."""
    severity: str  # info, warning, critical
    category: str
    message: str
    action: str


class ContextAnalyzer:
    """Analyzes context usage and provides recommendations."""
    
    # Approximate context limits by model
    CONTEXT_LIMITS = {
        "claude": 200_000,
        "gpt4": 128_000,
        "default": 100_000
    }
    
    def __init__(self, model: str = "claude"):
        self.model = model
        self.context_limit = self.CONTEXT_LIMITS.get(model, self.CONTEXT_LIMITS["default"])
    
    def estimate_tokens(self, text: str) -> int:
        """Estimate token count (roughly 4 chars per token)."""
        return len(text) // 4
    
    def analyze_file(self, file_path: Path) -> int:
        """Analyze a single file and return estimated tokens."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return self.estimate_tokens(content)
        except Exception:
            return 0
    
    def analyze_documentation(self, doc_dir: Path) -> dict:
        """Analyze documentation directory."""
        results = {
            "total_tokens": 0,
            "files": {}
        }
        
        doc_patterns = ["*.md", "*.txt", "*.json", "*.yaml", "*.yml"]
        
        for pattern in doc_patterns:
            for file_path in doc_dir.rglob(pattern):
                tokens = self.analyze_file(file_path)
                results["files"][str(file_path)] = tokens
                results["total_tokens"] += tokens
        
        return results
    
    def generate_recommendations(self, metrics: ContextMetrics) -> List[ContextRecommendation]:
        """Generate recommendations based on metrics."""
        recommendations = []
        
        # Check overall usage
        if metrics.estimated_usage_percent > 80:
            recommendations.append(ContextRecommendation(
                severity="critical",
                category="context_exhaustion",
                message=f"Context usage at {metrics.estimated_usage_percent:.1f}% - approaching limit",
                action="Start new session or aggressively compact current context"
            ))
        elif metrics.estimated_usage_percent > 60:
            recommendations.append(ContextRecommendation(
                severity="warning",
                category="context_pressure",
                message=f"Context usage at {metrics.estimated_usage_percent:.1f}%",
                action="Consider summarizing older conversation or offloading to files"
            ))
        
        # Check message count
        if metrics.message_count > 30:
            recommendations.append(ContextRecommendation(
                severity="warning",
                category="session_length",
                message=f"Session has {metrics.message_count} messages",
                action="Consider saving context and starting fresh session"
            ))
        
        # Check conversation ratio
        conversation_ratio = metrics.conversation_tokens / max(metrics.total_tokens, 1)
        if conversation_ratio > 0.5:
            recommendations.append(ContextRecommendation(
                severity="info",
                category="conversation_heavy",
                message=f"Conversation history is {conversation_ratio:.0%} of context",
                action="Summarize older messages to free up space for tools/docs"
            ))
        
        # Check tool output ratio
        tool_ratio = metrics.tool_output_tokens / max(metrics.total_tokens, 1)
        if tool_ratio > 0.3:
            recommendations.append(ContextRecommendation(
                severity="info",
                category="tool_heavy",
                message=f"Tool outputs are {tool_ratio:.0%} of context",
                action="Save large tool outputs to files, keep summaries in context"
            ))
        
        # Check session duration
        if metrics.session_duration_minutes > 120:
            recommendations.append(ContextRecommendation(
                severity="info",
                category="long_session",
                message=f"Session running for {metrics.session_duration_minutes:.0f} minutes",
                action="Consider periodic context saves to prevent loss"
            ))
        
        return recommendations
    
    def print_report(self, metrics: ContextMetrics, recommendations: List[ContextRecommendation]):
        """Print formatted analysis report."""
        print("\n" + "=" * 60)
        print("CONTEXT ANALYSIS REPORT")
        print("=" * 60)
        
        print(f"\nüìä METRICS")
        print(f"   Total tokens: {metrics.total_tokens:,}")
        print(f"   Context usage: {metrics.estimated_usage_percent:.1f}%")
        print(f"   Message count: {metrics.message_count}")
        print(f"   Session duration: {metrics.session_duration_minutes:.0f} min")
        
        print(f"\nüìà TOKEN BREAKDOWN")
        print(f"   Conversation: {metrics.conversation_tokens:,} ({metrics.conversation_tokens/max(metrics.total_tokens,1):.0%})")
        print(f"   Documentation: {metrics.documentation_tokens:,} ({metrics.documentation_tokens/max(metrics.total_tokens,1):.0%})")
        print(f"   Memory: {metrics.memory_tokens:,} ({metrics.memory_tokens/max(metrics.total_tokens,1):.0%})")
        print(f"   Tool outputs: {metrics.tool_output_tokens:,} ({metrics.tool_output_tokens/max(metrics.total_tokens,1):.0%})")
        
        if recommendations:
            print(f"\nüí° RECOMMENDATIONS")
            for rec in recommendations:
                icon = {"critical": "üî¥", "warning": "üü°", "info": "üîµ"}[rec.severity]
                print(f"\n   {icon} [{rec.category}]")
                print(f"      {rec.message}")
                print(f"      ‚Üí {rec.action}")
        else:
            print(f"\n‚úÖ No issues detected")
        
        print("\n" + "=" * 60)


def main():
    parser = argparse.ArgumentParser(description='Analyze context usage')
    parser.add_argument('--session-file', type=str, help='Path to session JSON file')
    parser.add_argument('--doc-dir', type=str, help='Path to documentation directory')
    parser.add_argument('--model', type=str, default='claude', 
                        choices=['claude', 'gpt4'], help='Model for context limits')
    parser.add_argument('--threshold', type=float, default=0.6,
                        help='Warning threshold (0-1)')
    
    args = parser.parse_args()
    
    analyzer = ContextAnalyzer(model=args.model)
    
    # Demo metrics if no files provided
    if not args.session_file and not args.doc_dir:
        print("No input provided. Showing demo analysis...")
        
        metrics = ContextMetrics(
            total_tokens=85_000,
            conversation_tokens=45_000,
            documentation_tokens=15_000,
            memory_tokens=5_000,
            tool_output_tokens=20_000,
            estimated_usage_percent=42.5,
            message_count=28,
            session_duration_minutes=75
        )
        
        recommendations = analyzer.generate_recommendations(metrics)
        analyzer.print_report(metrics, recommendations)
        return
    
    # Analyze documentation if provided
    if args.doc_dir:
        doc_path = Path(args.doc_dir)
        if doc_path.exists():
            results = analyzer.analyze_documentation(doc_path)
            
            print(f"\nüìÅ Documentation Analysis: {doc_path}")
            print(f"   Total files: {len(results['files'])}")
            print(f"   Total tokens: {results['total_tokens']:,}")
            
            # Show largest files
            sorted_files = sorted(results['files'].items(), key=lambda x: x[1], reverse=True)
            print(f"\n   Largest files:")
            for path, tokens in sorted_files[:5]:
                print(f"      {tokens:,} tokens - {path}")


if __name__ == '__main__':
    main()
